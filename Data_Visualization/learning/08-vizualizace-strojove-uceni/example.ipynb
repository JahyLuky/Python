{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52413626",
   "metadata": {},
   "source": [
    "# ğŸ™Œ PraktickÃ¡ ukÃ¡zka\n",
    "\n",
    "V tomto notebooku si vizualizace ukÃ¡Å¾eme na reÃ¡lnÃ©m modelu. VyuÅ¾ijeme k tomu ğŸ˜ [California Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) a ğŸŒ³ `DecisionTreeRegressor`.\n",
    "\n",
    "CÃ­lem tÃ©to ukÃ¡zky **nenÃ­** vytvoÅ™it skvÄ›lÃ½ ML model, zajÃ­majÃ­ nÃ¡s jenom vizualizace.\n",
    "\n",
    "ZaÄneme importem potÅ™ebnÃ½ch balÃ­ÄkÅ¯ a definicÃ­ barev, kterÃ© budeme dÃ¡le vyuÅ¾Ã­vat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "# model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# data generation and preparation\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# hyperparameter tuning\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# interactive elements\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "blue = '#8592dc'\n",
    "violet = '#9047A0'\n",
    "red = '#d14081'\n",
    "grey = '#8E8DB4'\n",
    "white = '#ffffff'\n",
    "black='#222222'\n",
    "green='#42aa78'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439559a",
   "metadata": {},
   "source": [
    "## ğŸ“š Dataset\n",
    "V datasetu mÃ¡me 8 numerickÃ½ch pÅ™Ã­znakÅ¯ a jednu vysvÄ›tlovanou promÄ›nnou MedHouseVal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "california = datasets.fetch_california_housing(as_frame=True)\n",
    "X = california.data\n",
    "y = california.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fae6d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "california.frame #shows data as DataFrame, when as_frame=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe45fe6",
   "metadata": {},
   "source": [
    "Data si rozdÄ›lÃ­me na trÃ©novacÃ­, validaÄnÃ­ a testovacÃ­. â˜ï¸ ValidaÄnÃ­ data pouÅ¾ijeme k ladÄ›nÃ­ hyperparametrÅ¯ a testovacÃ­ k vyhodnocenÃ­ finÃ¡lnÃ­ ÃºspÄ›Å¡nosti modelu (znÃ¡te z BI-ML1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, rd_seed=1234):\n",
    "    # split data to train (75%) and test (25%)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=rd_seed) \n",
    "    # split train data from previous step to train (75%) and validation (25%)\n",
    "    Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.25, random_state=rd_seed) \n",
    "    return Xtrain, Xtest, Xval, ytrain, ytest, yval\n",
    "\n",
    "Xtrain, Xtest, Xval, ytrain, ytest, yval = split_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db67bda",
   "metadata": {},
   "source": [
    "## ğŸ›  LadÄ›nÃ­ hyperparametrÅ¯\n",
    "\n",
    "Budeme ladit tÅ™i hyperparametry:\n",
    "* ğŸ‘‡ğŸ½ max_depth\n",
    "* ğŸƒ min_samples_leaf\n",
    "* ğŸ™…ğŸ½â€â™€ï¸ min_samples_split\n",
    "\n",
    "Na vygenerovÃ¡nÃ­ vÅ¡ech kombinacÃ­ tÄ›chto hyperparametrÅ¯ vyuÅ¾ijeme [`ParameterGrid`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) (tj. mÅ™Ã­Å¾ka parametrÅ¯ s diskrÃ©tnÃ­m poÄtem hodnot pro kaÅ¾dÃ½ z nich)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'max_depth': range(2,20,2),\n",
    "    'min_samples_leaf': [1, 3, 5, 7],\n",
    "    'min_samples_split': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "params_grid = ParameterGrid(params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696a14e",
   "metadata": {},
   "source": [
    "NynÃ­ vytvoÅ™Ã­me a nÃ¡slednÄ› zavolÃ¡me funkci `tune`, kterÃ¡ na zÃ¡kladÄ› trÃ©novacÃ­ch a validaÄnÃ­ch dat a kombinacÃ­ hyperparametrÅ¯, kterÃ© chceme zkusit, natrÃ©nuje rÅ¯znÃ© modely a zmÄ›Å™Ã­ jejich trÃ©novacÃ­ a validaÄnÃ­ chybu. Jako metriku jsme zvolili MSE (mean square error). Funkce vrÃ¡tÃ­ dvÄ› pole, `train_mse` (trÃ©novacÃ­ MSE) a `val_mse` (validaÄnÃ­ MSE).\n",
    "\n",
    "Hodnota `train_mse[i]` odpovÃ­dÃ¡ trÃ©novacÃ­ chybÄ› modelu s hyperparametry `params_comb[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc63b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(Xtrain, ytrain, Xval, yval, params_comb):\n",
    "    train_mse = []\n",
    "    val_mse = []\n",
    "\n",
    "    for params in params_comb:\n",
    "        dt = DecisionTreeRegressor(**params)\n",
    "        dt.fit(Xtrain, ytrain)\n",
    "        val_mse.append(metrics.mean_squared_error(yval, dt.predict(Xval)))\n",
    "        train_mse.append(metrics.mean_squared_error(ytrain, dt.predict(Xtrain)))\n",
    "        \n",
    "    return train_mse, val_mse\n",
    "\n",
    "train_mse, val_mse = tune(Xtrain, ytrain, Xval, yval, params_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f10c18",
   "metadata": {},
   "source": [
    "A teÄ je Äas na vizualizaci. UÅ¾ jsme si ukazovali, jak vykreslit vÃ½voj nÄ›jakÃ© metriky u jednoho hyperparametru. NynÃ­ jich mÃ¡me vÃ­c. NaÅ¡tÄ›stÃ­ mÅ¯Å¾eme pouÅ¾Ã­t ÃºplnÄ› stejnÃ½ graf. Osa x nynÃ­ zobrazuje index v poli vÅ¡ech kombinacÃ­ hyperparametrÅ¯.\n",
    "\n",
    "Pro lepÅ¡Ã­ pÅ™ehlednost lze pÅ™idat vertikÃ¡lnÃ­ ÄÃ¡ry, kterÃ© ukazujÃ­, kdy doÅ¡lo ke zmÄ›nÄ› hodnoty nÄ›jakÃ©ho hyperparametru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a682b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse(train_mse, val_mse):\n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "    for x in range(16,144,16):\n",
    "        plt.axvline(x=x, c=white, linewidth=3, label='max_depth change')\n",
    "    for x in range(4,144,4):\n",
    "        plt.axvline(x=x, c=white, label='min_samples_leaf change')\n",
    "\n",
    "    ax.plot(train_mse, 'o-', color=blue, label='train mse')\n",
    "    ax.plot(val_mse,'o-', color=violet, label='validation mse')\n",
    "\n",
    "    # legend with duplicated labels removed, for more info see:\n",
    "    # https://stackoverflow.com/questions/13588920/stop-matplotlib-repeating-labels-in-legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), facecolor=grey, framealpha=0.4)\n",
    "    \n",
    "    # styling  \n",
    "    ax.set_xlim(left=-1, right=144)\n",
    "    ax.set(facecolor = \"#eaeaf2\")\n",
    "    for key, spine in ax.spines.items():\n",
    "        spine.set_visible(False)  \n",
    "    \n",
    "    # labels\n",
    "    ax.set_xlabel('index in parameter array')\n",
    "    ax.set_ylabel('mean squared error')\n",
    "    ax.set_title('Train and test MSE for every hyperparameter combination')\n",
    "    \n",
    "plot_mse(train_mse, val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9232865",
   "metadata": {},
   "source": [
    "VypadÃ¡ to tak, Å¾e u malÃ½ch hloubek vÅ¯bec nezÃ¡leÅ¾elo na hodnotÃ¡ch ostatnÃ­ch hyperparametrÅ¯, protoÅ¾e se chybovost pÅ™Ã­liÅ¡ nemÄ›nila.\n",
    "\n",
    "V pravÃ© ÄÃ¡sti grafu, kde uÅ¾ je hloubka vÄ›tÅ¡Ã­, je vidÄ›t i vliv hyperparametru ğŸƒ `min_samples_leaf`.\n",
    "S narÅ¯stajÃ­cÃ­ hodnotou hyperparametru na validaÄnÃ­ch datech MSE klesÃ¡ (s rostoucÃ­ hloubkou MSE vzroste) a na trÃ©novacÃ­ch MSE roste (s rostoucÃ­ hloubkou MSE klesÃ¡). To svÄ›dÄÃ­ o tom, Å¾e stromy, kterÃ½m jsme dovolili vytvÃ¡Å™et listy s malÃ½m poÄtem pozorovÃ¡nÃ­, byly pÅ™euÄeny.\n",
    "\n",
    "NynÃ­ se mÅ¯Å¾eme posunout dÃ¡l a **vybrat nejlepÅ¡Ã­ hyperparametry**. To jsou ty, kterÃ© byly pouÅ¾ity k natrÃ©novÃ¡nÃ­ modelu s nejniÅ¾Å¡Ã­ **validaÄnÃ­ MSE**. Na tÄ›chto hyperparametrech znovu natrÃ©nujeme model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = params_grid[np.argmin(val_mse)]\n",
    "print('NejlepÅ¡Ã­ hyperparametry pro validaÄnÃ­ data jsou:', best_params)\n",
    "\n",
    "dt = DecisionTreeRegressor(**best_params)\n",
    "dt.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eddcac",
   "metadata": {},
   "source": [
    "## âš–ï¸ Evaluace\n",
    "ZaÄneme tÃ­m, Å¾e vytvoÅ™Ã­me predikce pro trÃ©novacÃ­, validaÄnÃ­ a testovacÃ­ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee27fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred = dt.predict(Xtrain)\n",
    "yval_pred = dt.predict(Xval)\n",
    "ytest_pred = dt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097c650",
   "metadata": {},
   "source": [
    "Pro vÅ¡echny tÅ™i mnoÅ¾iny dat nynÃ­ mÃ¡me reÃ¡lnÃ© hodnoty i predikce. MÅ¯Å¾eme tak vytvoÅ™it `DataFrame`, kterÃ½ obsahuje reÃ¡lnou a predikovanou hodnotu, jejich rozdÃ­l (chybu) a informaci o tom, do kterÃ© mnoÅ¾iny data patÅ™Ã­. ğŸ•µğŸ»â€â™‚ï¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_df(yreal, ypred, subset):\n",
    "    df = pd.DataFrame()\n",
    "    df['real'] = yreal\n",
    "    df['predicted'] = ypred\n",
    "    df['error'] = yreal - ypred\n",
    "    df['set'] = subset\n",
    "    return df\n",
    "    \n",
    "df = pd.concat([\n",
    "    create_error_df(ytrain, ytrain_pred, 'train'),\n",
    "    create_error_df(yval, yval_pred, 'validation'),\n",
    "    create_error_df(ytest, ytest_pred, 'test'),\n",
    "])\n",
    "\n",
    "display(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56b57c",
   "metadata": {},
   "source": [
    "ZÃ¡vaÅ¾nost chyby budeme poÄÃ­tat s ohledem na rozsah vysvÄ›tlovanÃ© promÄ›nnÃ©. KaÅ¾dou chybu vydÄ›lÃ­me rozdÃ­lem maximÃ¡lnÃ­ a minimÃ¡lnÃ­ hodnoty na trÃ©novacÃ­ mnoÅ¾inÄ›."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized_error'] = df.error / (ytrain.max() - ytrain.min())\n",
    "df['normalized_error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e659f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_severity(row):\n",
    "    if abs(row.normalized_error) < 0.1:\n",
    "        return 'low'\n",
    "    if abs(row.normalized_error) < 0.3:\n",
    "        return 'medium'\n",
    "    return 'high'\n",
    "\n",
    "df['severity'] = df.apply(compute_severity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd63bc",
   "metadata": {},
   "source": [
    "V notebooku `evaluations.ipynb` jsme si ukÃ¡zali, jak vytvoÅ™it graf reÃ¡lnÃ© a predikovanÃ© hodnoty. NynÃ­ do tohoto grafu pÅ™idÃ¡me takÃ© informaci o zÃ¡vaÅ¾nosti chyby, kterou budeme zobrazovat pomocÃ­ barvy. Abychom mohli porovnat trÃ©novacÃ­, validaÄnÃ­ a testovacÃ­ chybovost, pro kaÅ¾dou z tÄ›chto mnoÅ¾in vytvoÅ™Ã­me samostatnÃ½ graf. PomocÃ­ interaktivnÃ­ch prvkÅ¯ umoÅ¾nÃ­me vÃ½bÄ›r mnoÅ¾iny, pro kterou se graf zobrazÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035aa5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_pred_interactive(dataframe):\n",
    "    \n",
    "    def plot_real_pred(subset):\n",
    "        df = dataframe[dataframe.set == subset]\n",
    "        with plt.style.context('seaborn-darkgrid'):\n",
    "            low = df[df.severity == 'low']\n",
    "            medium = df[df.severity == 'medium']\n",
    "            high = df[df.severity == 'high']\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(16,8))\n",
    "            ax.plot([0,5.5],[0,5.5], color=black, label='x = y')\n",
    "            ax.scatter(low.real, low.predicted, color=green, alpha=0.15, label='Low severity')\n",
    "            ax.scatter(medium.real, medium.predicted, color=blue, alpha=0.15, label='Medium severity')\n",
    "            ax.scatter(high.real, high.predicted, color=red, alpha=0.15, label='High severity')\n",
    "\n",
    "            ax.set_xlabel('Real value')\n",
    "            ax.set_ylabel('Predicted value')\n",
    "            ax.legend()\n",
    "            ax.set_title('Error visualization for {} batch'.format(subset))\n",
    "\n",
    "    interact(plot_real_pred, subset=['train', 'validation', 'test'])\n",
    "    \n",
    "plot_real_pred_interactive(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc515ce",
   "metadata": {},
   "source": [
    "Na prvnÃ­ pohled je vidÄ›t, Å¾e na validaÄnÃ­ch a testovacÃ­ch datech mÃ¡me v porovnÃ¡nÃ­ s trÃ©novacÃ­mi vÃ­ce velkÃ½ch chyb (vizualizovanÃ½ch Äervenou barvou).\n",
    "\n",
    "PojÄme se podÃ­vat na distribuci chyby. VykreslÃ­me si violin plot a normalizovanÃ½ histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn default theme with dark grid\n",
    "sns.set_theme()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "sns.violinplot(ax=ax, data=df, x='set', y='error', palette='Set2')\n",
    "\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_xlabel('Set')\n",
    "_ = ax.set_title('Error across sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f93c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "sns.histplot(\n",
    "    df, binwidth=0.05, x='error', hue='set', palette='Set2', \n",
    "    element='step', ax=ax, stat='probability', common_norm=False,\n",
    ")\n",
    "\n",
    "# stat='probability' - normalize such that bar heights sum to 1\n",
    "\n",
    "ax.set_xlabel('Error')\n",
    "ax.set_ylabel('Normalized count')\n",
    "_ = ax.set_title('Normalized histogram of error across sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c9c14",
   "metadata": {},
   "source": [
    "Z obou grafÅ¯ vidÃ­me, Å¾e na trÃ©novacÃ­ch datech model funguje nejlÃ©pe (vÄ›tÅ¡ina chyb je velmi malÃ½ch a vÄ›tÅ¡Ã­ chyby nastÃ¡vajÃ­ mÃ©nÄ› Äasto). Na validaÄnÃ­ a testovacÃ­ mnoÅ¾inÄ› dÄ›lal model pÅ™ibliÅ¾nÄ› stejnÃ© chyby. Na obou mnoÅ¾inÃ¡ch jsou vÄ›tÅ¡Ã­ chyby frekventovanÄ›jÅ¡Ã­ neÅ¾ na trÃ©novacÃ­ mnoÅ¾inÄ›.\n",
    "\n",
    "Jako poslednÃ­ vizualizaci vykreslÃ­me vÃ½slednÃ½ model pomocÃ­ balÃ­Äku `dtreeviz` ğŸŒ³. JelikoÅ¾ mÃ¡ model velkou hloubku, je rozumnÃ© nezobrazovat bodovÃ© grafy v kaÅ¾dÃ©m vrcholu, ale pouze v listech. Toho dosÃ¡hneme pomocÃ­ parametru `fancy=False`. I tak si na vizualizaci budeme muset chvÃ­li poÄkat ğŸ•’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35450fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(\n",
    "    dt, Xtrain, ytrain,\n",
    "    target_name='price',\n",
    "    feature_names=california.feature_names,\n",
    "    class_names=list(california.target_names),\n",
    "    scale=1.5,\n",
    "    fancy=False\n",
    ")\n",
    "\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e490168",
   "metadata": {},
   "source": [
    "## ğŸ‰ Pro dneÅ¡ek mÃ¡me hotovo! ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
