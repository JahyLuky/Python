{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52413626",
   "metadata": {},
   "source": [
    "# 🙌 Praktická ukázka\n",
    "\n",
    "V tomto notebooku si vizualizace ukážeme na reálném modelu. Využijeme k tomu 🏘 [California Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) a 🌳 `DecisionTreeRegressor`.\n",
    "\n",
    "Cílem této ukázky **není** vytvořit skvělý ML model, zajímají nás jenom vizualizace.\n",
    "\n",
    "Začneme importem potřebných balíčků a definicí barev, které budeme dále využívat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "# model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# data generation and preparation\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# hyperparameter tuning\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# interactive elements\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee70ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "blue = '#8592dc'\n",
    "violet = '#9047A0'\n",
    "red = '#d14081'\n",
    "grey = '#8E8DB4'\n",
    "white = '#ffffff'\n",
    "black='#222222'\n",
    "green='#42aa78'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439559a",
   "metadata": {},
   "source": [
    "## 📚 Dataset\n",
    "V datasetu máme 8 numerických příznaků a jednu vysvětlovanou proměnnou MedHouseVal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "california = datasets.fetch_california_housing(as_frame=True)\n",
    "X = california.data\n",
    "y = california.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fae6d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "california.frame #shows data as DataFrame, when as_frame=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe45fe6",
   "metadata": {},
   "source": [
    "Data si rozdělíme na trénovací, validační a testovací. ☝️ Validační data použijeme k ladění hyperparametrů a testovací k vyhodnocení finální úspěšnosti modelu (znáte z BI-ML1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d84b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, rd_seed=1234):\n",
    "    # split data to train (75%) and test (25%)\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25, random_state=rd_seed) \n",
    "    # split train data from previous step to train (75%) and validation (25%)\n",
    "    Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.25, random_state=rd_seed) \n",
    "    return Xtrain, Xtest, Xval, ytrain, ytest, yval\n",
    "\n",
    "Xtrain, Xtest, Xval, ytrain, ytest, yval = split_data(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db67bda",
   "metadata": {},
   "source": [
    "## 🛠 Ladění hyperparametrů\n",
    "\n",
    "Budeme ladit tři hyperparametry:\n",
    "* 👇🏽 max_depth\n",
    "* 🍃 min_samples_leaf\n",
    "* 🙅🏽‍♀️ min_samples_split\n",
    "\n",
    "Na vygenerování všech kombinací těchto hyperparametrů využijeme [`ParameterGrid`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ParameterGrid.html) (tj. mřížka parametrů s diskrétním počtem hodnot pro každý z nich)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6bc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    'max_depth': range(2,20,2),\n",
    "    'min_samples_leaf': [1, 3, 5, 7],\n",
    "    'min_samples_split': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "params_grid = ParameterGrid(params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696a14e",
   "metadata": {},
   "source": [
    "Nyní vytvoříme a následně zavoláme funkci `tune`, která na základě trénovacích a validačních dat a kombinací hyperparametrů, které chceme zkusit, natrénuje různé modely a změří jejich trénovací a validační chybu. Jako metriku jsme zvolili MSE (mean square error). Funkce vrátí dvě pole, `train_mse` (trénovací MSE) a `val_mse` (validační MSE).\n",
    "\n",
    "Hodnota `train_mse[i]` odpovídá trénovací chybě modelu s hyperparametry `params_comb[i]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc63b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(Xtrain, ytrain, Xval, yval, params_comb):\n",
    "    train_mse = []\n",
    "    val_mse = []\n",
    "\n",
    "    for params in params_comb:\n",
    "        dt = DecisionTreeRegressor(**params)\n",
    "        dt.fit(Xtrain, ytrain)\n",
    "        val_mse.append(metrics.mean_squared_error(yval, dt.predict(Xval)))\n",
    "        train_mse.append(metrics.mean_squared_error(ytrain, dt.predict(Xtrain)))\n",
    "        \n",
    "    return train_mse, val_mse\n",
    "\n",
    "train_mse, val_mse = tune(Xtrain, ytrain, Xval, yval, params_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f10c18",
   "metadata": {},
   "source": [
    "A teď je čas na vizualizaci. Už jsme si ukazovali, jak vykreslit vývoj nějaké metriky u jednoho hyperparametru. Nyní jich máme víc. Naštěstí můžeme použít úplně stejný graf. Osa x nyní zobrazuje index v poli všech kombinací hyperparametrů.\n",
    "\n",
    "Pro lepší přehlednost lze přidat vertikální čáry, které ukazují, kdy došlo ke změně hodnoty nějakého hyperparametru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a682b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse(train_mse, val_mse):\n",
    "    fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "    for x in range(16,144,16):\n",
    "        plt.axvline(x=x, c=white, linewidth=3, label='max_depth change')\n",
    "    for x in range(4,144,4):\n",
    "        plt.axvline(x=x, c=white, label='min_samples_leaf change')\n",
    "\n",
    "    ax.plot(train_mse, 'o-', color=blue, label='train mse')\n",
    "    ax.plot(val_mse,'o-', color=violet, label='validation mse')\n",
    "\n",
    "    # legend with duplicated labels removed, for more info see:\n",
    "    # https://stackoverflow.com/questions/13588920/stop-matplotlib-repeating-labels-in-legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), facecolor=grey, framealpha=0.4)\n",
    "    \n",
    "    # styling  \n",
    "    ax.set_xlim(left=-1, right=144)\n",
    "    ax.set(facecolor = \"#eaeaf2\")\n",
    "    for key, spine in ax.spines.items():\n",
    "        spine.set_visible(False)  \n",
    "    \n",
    "    # labels\n",
    "    ax.set_xlabel('index in parameter array')\n",
    "    ax.set_ylabel('mean squared error')\n",
    "    ax.set_title('Train and test MSE for every hyperparameter combination')\n",
    "    \n",
    "plot_mse(train_mse, val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9232865",
   "metadata": {},
   "source": [
    "Vypadá to tak, že u malých hloubek vůbec nezáleželo na hodnotách ostatních hyperparametrů, protože se chybovost příliš neměnila.\n",
    "\n",
    "V pravé části grafu, kde už je hloubka větší, je vidět i vliv hyperparametru 🍃 `min_samples_leaf`.\n",
    "S narůstající hodnotou hyperparametru na validačních datech MSE klesá (s rostoucí hloubkou MSE vzroste) a na trénovacích MSE roste (s rostoucí hloubkou MSE klesá). To svědčí o tom, že stromy, kterým jsme dovolili vytvářet listy s malým počtem pozorování, byly přeučeny.\n",
    "\n",
    "Nyní se můžeme posunout dál a **vybrat nejlepší hyperparametry**. To jsou ty, které byly použity k natrénování modelu s nejnižší **validační MSE**. Na těchto hyperparametrech znovu natrénujeme model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = params_grid[np.argmin(val_mse)]\n",
    "print('Nejlepší hyperparametry pro validační data jsou:', best_params)\n",
    "\n",
    "dt = DecisionTreeRegressor(**best_params)\n",
    "dt.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eddcac",
   "metadata": {},
   "source": [
    "## ⚖️ Evaluace\n",
    "Začneme tím, že vytvoříme predikce pro trénovací, validační a testovací data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee27fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_pred = dt.predict(Xtrain)\n",
    "yval_pred = dt.predict(Xval)\n",
    "ytest_pred = dt.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c097c650",
   "metadata": {},
   "source": [
    "Pro všechny tři množiny dat nyní máme reálné hodnoty i predikce. Můžeme tak vytvořit `DataFrame`, který obsahuje reálnou a predikovanou hodnotu, jejich rozdíl (chybu) a informaci o tom, do které množiny data patří. 🕵🏻‍♂️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9996aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_df(yreal, ypred, subset):\n",
    "    df = pd.DataFrame()\n",
    "    df['real'] = yreal\n",
    "    df['predicted'] = ypred\n",
    "    df['error'] = yreal - ypred\n",
    "    df['set'] = subset\n",
    "    return df\n",
    "    \n",
    "df = pd.concat([\n",
    "    create_error_df(ytrain, ytrain_pred, 'train'),\n",
    "    create_error_df(yval, yval_pred, 'validation'),\n",
    "    create_error_df(ytest, ytest_pred, 'test'),\n",
    "])\n",
    "\n",
    "display(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56b57c",
   "metadata": {},
   "source": [
    "Závažnost chyby budeme počítat s ohledem na rozsah vysvětlované proměnné. Každou chybu vydělíme rozdílem maximální a minimální hodnoty na trénovací množině."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d9e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized_error'] = df.error / (ytrain.max() - ytrain.min())\n",
    "df['normalized_error'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e659f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_severity(row):\n",
    "    if abs(row.normalized_error) < 0.1:\n",
    "        return 'low'\n",
    "    if abs(row.normalized_error) < 0.3:\n",
    "        return 'medium'\n",
    "    return 'high'\n",
    "\n",
    "df['severity'] = df.apply(compute_severity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd63bc",
   "metadata": {},
   "source": [
    "V notebooku `evaluations.ipynb` jsme si ukázali, jak vytvořit graf reálné a predikované hodnoty. Nyní do tohoto grafu přidáme také informaci o závažnosti chyby, kterou budeme zobrazovat pomocí barvy. Abychom mohli porovnat trénovací, validační a testovací chybovost, pro každou z těchto množin vytvoříme samostatný graf. Pomocí interaktivních prvků umožníme výběr množiny, pro kterou se graf zobrazí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035aa5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_real_pred_interactive(dataframe):\n",
    "    \n",
    "    def plot_real_pred(subset):\n",
    "        df = dataframe[dataframe.set == subset]\n",
    "        with plt.style.context('seaborn-darkgrid'):\n",
    "            low = df[df.severity == 'low']\n",
    "            medium = df[df.severity == 'medium']\n",
    "            high = df[df.severity == 'high']\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(16,8))\n",
    "            ax.plot([0,5.5],[0,5.5], color=black, label='x = y')\n",
    "            ax.scatter(low.real, low.predicted, color=green, alpha=0.15, label='Low severity')\n",
    "            ax.scatter(medium.real, medium.predicted, color=blue, alpha=0.15, label='Medium severity')\n",
    "            ax.scatter(high.real, high.predicted, color=red, alpha=0.15, label='High severity')\n",
    "\n",
    "            ax.set_xlabel('Real value')\n",
    "            ax.set_ylabel('Predicted value')\n",
    "            ax.legend()\n",
    "            ax.set_title('Error visualization for {} batch'.format(subset))\n",
    "\n",
    "    interact(plot_real_pred, subset=['train', 'validation', 'test'])\n",
    "    \n",
    "plot_real_pred_interactive(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc515ce",
   "metadata": {},
   "source": [
    "Na první pohled je vidět, že na validačních a testovacích datech máme v porovnání s trénovacími více velkých chyb (vizualizovaných červenou barvou).\n",
    "\n",
    "Pojďme se podívat na distribuci chyby. Vykreslíme si violin plot a normalizovaný histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn default theme with dark grid\n",
    "sns.set_theme()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "sns.violinplot(ax=ax, data=df, x='set', y='error', palette='Set2')\n",
    "\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_xlabel('Set')\n",
    "_ = ax.set_title('Error across sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f93c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "sns.histplot(\n",
    "    df, binwidth=0.05, x='error', hue='set', palette='Set2', \n",
    "    element='step', ax=ax, stat='probability', common_norm=False,\n",
    ")\n",
    "\n",
    "# stat='probability' - normalize such that bar heights sum to 1\n",
    "\n",
    "ax.set_xlabel('Error')\n",
    "ax.set_ylabel('Normalized count')\n",
    "_ = ax.set_title('Normalized histogram of error across sets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c9c14",
   "metadata": {},
   "source": [
    "Z obou grafů vidíme, že na trénovacích datech model funguje nejlépe (většina chyb je velmi malých a větší chyby nastávají méně často). Na validační a testovací množině dělal model přibližně stejné chyby. Na obou množinách jsou větší chyby frekventovanější než na trénovací množině.\n",
    "\n",
    "Jako poslední vizualizaci vykreslíme výsledný model pomocí balíčku `dtreeviz` 🌳. Jelikož má model velkou hloubku, je rozumné nezobrazovat bodové grafy v každém vrcholu, ale pouze v listech. Toho dosáhneme pomocí parametru `fancy=False`. I tak si na vizualizaci budeme muset chvíli počkat 🕒."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35450fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(\n",
    "    dt, Xtrain, ytrain,\n",
    "    target_name='price',\n",
    "    feature_names=california.feature_names,\n",
    "    class_names=list(california.target_names),\n",
    "    scale=1.5,\n",
    "    fancy=False\n",
    ")\n",
    "\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e490168",
   "metadata": {},
   "source": [
    "## 🎉 Pro dnešek máme hotovo! 🎉"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
