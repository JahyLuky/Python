{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3533851d",
   "metadata": {},
   "source": [
    "# 📊 Vizualizace modelů strojového učení\n",
    "V tomto notebooku si ukážeme jak vytvořit vizualizace některých klasifikačních a regresních modelů a jak díky vzniklým vizualizacím lépe pochopit, jak se dané modely rozhodují."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import neighbors\n",
    "\n",
    "# data generation\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from dtreeviz.trees import dtreeviz\n",
    "import graphviz\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab840005",
   "metadata": {},
   "source": [
    "## 🌳 Rozhodovací strom\n",
    "Začneme jedním z nejznámějších ML modelů – rozhodovací strom. V balíčku `sklearn` existují dvě varianty tohoto modelu, jedna na klasifikaci ([`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)) a jedna na regresi ([`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)).\n",
    "\n",
    "### 🅰️ 🅱️ Klasifikace\n",
    "Rozhodovací strom natrénujeme co nejjednodušším způsobem na datasetu [Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) 🌹, který si načteme přímo pomocí funkce [`sklearn.datasets.load_iris()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html). Dataset obsahuje celkem 150 záznamů, které můžeme klasifikovat do 3 tříd na základě 4 příznaků."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data acquisition\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15709e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4005f09",
   "metadata": {},
   "source": [
    "Rozhodovací strom sice máme natrénovaný, ale nevíme vůbec nic o tom, podle čeho predikuje. To lze vyřešit tím, že zobrazíme jeho strukturu. Z přednášky víme, že `sklearn` nabízí dva způsoby pro vizualizaci rozhodovacího stromu – textovou a grafickou reprezentaci.\n",
    "\n",
    "📖 **Textovou reprezentaci** dostaneme pomocí funkce `export_text`. Formát jejího výstupu můžeme ovlivnit pomocí parametrů, např.:\n",
    "* feature_names - názvy příznaků, které se mají použít (pokud žádné nezadáme, použijí se generické názvy feature_1, feature_2, ...)\n",
    "* max_dept - počet hladin, které mají být zahrnuty do exportu\n",
    "* spacing - počet mezer, které slouží k odsazení hran (čím vyšší, tím širší výsledek)\n",
    "* decimals - počet míst za desetinnou čárkou, která se mají zobrazit\n",
    "\n",
    "Pro více informací si prohlédněte dokumentaci.\n",
    "\n",
    "🗂 [textová reprezentace](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207f10f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_representation = tree.export_text(clf, feature_names=iris.feature_names)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a89b9a",
   "metadata": {},
   "source": [
    "🖌 **Grafickou reprezentaci** získáme pomocí funkce `plot_tree`. Formát jejího výstupu můžeme ovlivnit pomocí parametrů, např.:\n",
    "* filled\n",
    "    * pokud se nastaví na True, vrcholy stromu se obarví\n",
    "    * v případě klasifikace zabarvení indikuje majoritní třídu\n",
    "* rounded - pokud se nastaví na True, vrcholy budou vykresleny se zaoblenými rohy\n",
    "* proportion - pokud se nastaví na True, values a samples se budou zobrazovat procentuálně\n",
    "* ax\n",
    "   * specifikuje Axes, do které se má graf vykreslit\n",
    "   * pokud není zadaná, použije se aktuální Axes\n",
    "\n",
    "Všechny ostatní možnosti si můžete prohlédnout v dokumentaci. Obsah popisků jednotlivých uzlů jsme probírali na přednášce. \n",
    "\n",
    "🗂 [grafická reprezentace](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "_ = tree.plot_tree(\n",
    "    clf, \n",
    "    feature_names=iris.feature_names,  \n",
    "    class_names=iris.target_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb78f85",
   "metadata": {},
   "source": [
    "V přednášce jsme si zmínili knihovnu [dtreeviz](https://github.com/parrt/dtreeviz). Rozhodovací strom vykreslíme pomocí funkce `dtreeviz`, které zadáme model a vstupní data (matice příznaků a vektor s vysvětlovanou proměnnou). Dále můžeme specifikovat orientaci (např. 'LR' znamená zleva doprava), `target_name`, `feature_names` a v případě klasifikace `class_names`.\n",
    "\n",
    "Pokud zadáme i parametr X (jedno pozorování), ve vizualizaci se vyznačí rozhodovací cesta (všechny vrcholy, kterými toto pozorování prošlo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed31b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(\n",
    "    clf, X, y,\n",
    "    target_name='variety',\n",
    "    feature_names=iris.feature_names,\n",
    "    class_names=list(iris.target_names),\n",
    "    scale=1.5\n",
    ")\n",
    "\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[100], y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8845148",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(\n",
    "    clf, X, y,\n",
    "    target_name='variety',\n",
    "    feature_names=iris.feature_names,\n",
    "    class_names=list(iris.target_names),\n",
    "    scale=1.5,\n",
    "    # if you provide specific datapoint, you can visualize prediction path\n",
    "    X=X[100]\n",
    ")\n",
    "\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c0e5b",
   "metadata": {},
   "source": [
    "Knihovna toho obsahuje mnohem víc, než jsme si ukázali. V případě zájmu se můžete podívat na její [GitHub repozitář](https://github.com/parrt/dtreeviz). Nejzajímavější bude nejspíš složka [notebooks](https://github.com/parrt/dtreeviz/tree/master/notebooks).\n",
    "\n",
    "### 💯 Regrese\n",
    "Rozhodovací strom natrénujeme co nejjednodušším způsobem na datasetu [California Housing](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) 🏠. Dataset obsahuje 20 640 záznamů, 8 příznaků a spojitou výstupní proměnnou (cena nemovitosti).\n",
    "\n",
    "Vizualizace rozhodovacího stromu pro klasifikaci a regresi je stejná. Můžeme použít `sklearn` funkce `export_text` či `plot_tree`. V případě regrese se zabarvení vrcholu vypočítá dle atributu `value` (čím vyšší hodnota, tím sytější barva)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0a6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data acquisition\n",
    "california = datasets.fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ff7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "reg = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
    "reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d811ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_representation = tree.export_text(reg, feature_names=california.feature_names)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "_ = tree.plot_tree(\n",
    "    reg, \n",
    "    feature_names=california.feature_names,  \n",
    "    class_names=california.target_names,\n",
    "    filled=True,\n",
    "    ax=ax\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e84044",
   "metadata": {},
   "source": [
    "Úplně analogicky jako pro klasifikátor funguje také vizualizace regresního rozhodovacího stromu pomocí `dtreeviz`.\n",
    "\n",
    "☝️ V případě, že se vám kvůli této vizualizaci laguje notebook, můžete to vyřešit tím, že si označíte buňku a kliknete na `Cell > Current Outputs > Clear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = dtreeviz(\n",
    "    reg, X, y,\n",
    "    target_name='price',\n",
    "    feature_names=california.feature_names,\n",
    "    class_names=list(california.target_names),\n",
    "    scale=1.5\n",
    ")\n",
    "\n",
    "viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad230a3",
   "metadata": {},
   "source": [
    "## 🏘 k-NN pro klasifikaci\n",
    "Jak jsme si říkali na přednášce, k-NN pro klasifikaci (a vlastně všechny klasifikátory, které se rozhodují podle zobrazitelného počtu příznaků) lze vizualizovat pomocí rozhodovací hranice.\n",
    "\n",
    "Rozhodovací hranici můžeme vykreslit pomocí funkce `plot_decision_regions` z balíčku `mlxtend`.\n",
    "\n",
    "🗂 [dokumentace](http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.plotting/#plot_decision_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c84b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "X,y = make_classification(\n",
    "    n_samples=200, \n",
    "    n_features=2, \n",
    "    n_informative=2,\n",
    "    n_redundant=0, \n",
    "    n_repeated=0, \n",
    "    n_classes=2, \n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=1,\n",
    "    flip_y=0.1, \n",
    "    random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4735758",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [[1,3,5],[11,21,49]]\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, nrows=2, constrained_layout=True, figsize=(16,8))\n",
    "for row in range(2):\n",
    "    for col in range(3):\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors=k[row][col])\n",
    "        # model training\n",
    "        clf.fit(X, y)\n",
    "        # visualization\n",
    "        plot_decision_regions(X, y, clf=clf, ax=axs[row, col], legend=1)\n",
    "        axs[row, col].set_title('k-NN with k='+ str(k[row][col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c117807",
   "metadata": {},
   "source": [
    "Z vizualizací lze vidět, jak počet sousedů (_k_) ovlivňuje predikce modelu. V případě malého _k_ je model přeučený a rozhodovací hranice je komplikovaná. S narůstajícím _k_ se rozhodovací hranice postupně vyhlazuje.\n",
    "\n",
    "## ⭐️ Lineární regrese\n",
    "Začneme tím, že si vygenerujeme a zobrazíme data a následně na vzniklých datech natrénujeme co nejjednodušším způsobem model lineární regrese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67899ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# styling\n",
    "blue = '#8592dc'\n",
    "violet = '#9047A0'\n",
    "red = '#d14081'\n",
    "\n",
    "plt.rcParams.update({\"axes.grid\" : True})\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=[blue, violet, red])\n",
    "plt.style.use('seaborn-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "rng = np.random.RandomState(1)\n",
    "x = 10 * rng.rand(50)\n",
    "y = 2 * x - 5 + rng.randn(50)\n",
    "\n",
    "# reshaping for scikit learn models\n",
    "x = x.reshape(-1, 1)\n",
    "# Reshape your data either x.reshape(-1, 1) if your data has a single feature/column \n",
    "# and x.reshape(1, -1) if it contains a single sample.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9029668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00efa900",
   "metadata": {},
   "source": [
    "###  Lineární regrese pro jeden příznak\n",
    "\n",
    "Z přednášky víme, že lineární regresi s jedním příznakem lze vizualizovat pomocí regresní přímky. Jak ji dostaneme? Jednoduše: Vygenerujeme si \"rozumný\" (🙈) počet hodnot v intervalu $<x_{min}, x_{max}>$ a jako _y_ hodnotu dosadíme predikci modelu pro danou souřadnici _x_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9c948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 10, 1000).reshape(-1, 1) #(start, stop, num)\n",
    "yfit = model.predict(xfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346e7a3",
   "metadata": {},
   "source": [
    "Vizualizace může být jednoduchá: Vykreslíme data a regresní přímku v jednom grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4424a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# data\n",
    "ax.scatter(x, y)\n",
    "\n",
    "# regression line\n",
    "ax.plot(xfit, yfit, c=violet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3301a3",
   "metadata": {},
   "source": [
    "### Nelineární vztah\n",
    "Pokud je mezi proměnnými _x_ a _y_ nelineární vztah, stále tento problém můžeme modelovat pomocí lineární regrese z balíčku `sklearn`. Pojďme si nejprve vygenerovat příslušná data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "x = 10 * rng.rand(50)\n",
    "y = np.sin(x) + 0.1 * rng.randn(50)\n",
    "\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf8e8c",
   "metadata": {},
   "source": [
    "Co se stane, když se budeme snažit natrénovat obyčejnou lineární regresi? Nebude příliš dobrá, protože takový vztah nelze popsat jednou přímkou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd67f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "\n",
    "# data generation\n",
    "xfit = np.linspace(0, 10, 1000).reshape(-1, 1)\n",
    "yfit = model.predict(xfit)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "_ = ax.plot(xfit, yfit, c=violet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a286b",
   "metadata": {},
   "source": [
    "Trik je v tom, že musíme vstupní data **nějak transformovat** (pomocí bázických funkcí). V tomto případě použijeme funkci:\n",
    "$$f_n(x)=x^n$$\n",
    "K této transformaci slouží třída `PolynomialFeatures`. Pojďme si na příkladu ukázat, jak funguje:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bb178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "feature = np.array([2, 3, 4])\n",
    "poly = PolynomialFeatures(3, include_bias=False)\n",
    "poly.fit_transform(feature[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e833c38",
   "metadata": {},
   "source": [
    "☝️ V třídě `PolynomialFeatures` první parametr (zadali jsme číslo 3) reprezentuje maximální stupeň vzniklého polynomu. V našem případě to tedy znamená, že kromě příznaku $x$ (proměnná `feature`), který jsme měli na počátku (hodnoty 2, 3, 4) vzniknou další dva příznaky $x^2$ a $x^3$.\n",
    "Výsledný vektor, který vidíme ve výstupu buňky tedy vznikl takto:\n",
    "$[[2, 2^2, 2^3],[3, 3^2, 3^3],[4, 4^2, 4^3]]$\n",
    "\n",
    "A jak tato transformace ovlivňuje výslednou regresi? Zkusme si vykreslit regresi pro maximální stupeň polynomu v intervalu $<1,6>$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, nrows=2, constrained_layout=True, figsize=(16,8))\n",
    "\n",
    "for i in range(6):\n",
    "    poly_model = make_pipeline(PolynomialFeatures(i+1), LinearRegression())\n",
    "    # model training\n",
    "    poly_model.fit(x, y)\n",
    "    # regression line y coordinates\n",
    "    yfit = poly_model.predict(xfit)\n",
    "    # visualization\n",
    "    axs[i//3, i%3].scatter(x, y)\n",
    "    axs[i//3, i%3].plot(xfit, yfit, c=violet)\n",
    "    axs[i//3, i%3].set_title('Polynomial degree: '+ str(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b1bed",
   "metadata": {},
   "source": [
    "### 📈 Regrese v 3D\n",
    "\n",
    "Lineární regresi můžeme zobrazit, i když máme dva příznaky. Vizualizace pak bude 3D a namísto přímky budeme **zobrazovat rovinu**.\n",
    "\n",
    "3D graf vytvoříme tak, že při vytváření Axes objektu nastavíme parametr `projection` na hodnotu '3d'. Pokud chceme, aby byl graf ineraktivní (např. aby se dal rotovat), můžeme to nastavit pomocí [magického příkazu](https://ipython.readthedocs.io/en/stable/interactive/magics.html) (angl. magic command) `%matplotlib notebook` ✨. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "x = 10 * rng.rand(100)\n",
    "y = 10 * rng.rand(100)\n",
    "\n",
    "data = np.column_stack((x, y))\n",
    "z = 3*x + y - 5 + rng.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ca7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes figure interactive\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "# note the use of projection='3d' parameter\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.set_facecolor('white')\n",
    "ax.scatter(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(data, z)\n",
    "\n",
    "# data generation\n",
    "xfit = np.linspace(0, 10, 100)\n",
    "yfit = np.linspace(0, 10, 100)\n",
    "\n",
    "datafit = [[xi,yi] for xi in xfit for yi in yfit]\n",
    "zfit = model.predict(datafit)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.set_facecolor('white')\n",
    "ax.scatter(x, y, z)\n",
    "ax.plot([row[0] for row in datafit], [row[1] for row in datafit], zfit, alpha=0.2, c=violet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7531c",
   "metadata": {},
   "source": [
    "# 🎉 A to je k modelům vše! 🎉 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
