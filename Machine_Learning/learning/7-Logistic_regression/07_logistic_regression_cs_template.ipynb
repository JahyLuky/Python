{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cvičení 7 - Logistická regrese\n",
    "\n",
    "V dnešním cvičení budeme zkoumat logistickou regresi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model pro binární klasifikaci\n",
    "\n",
    "Uvažme binární vysvětlovanou proměnnou $Y$ s hodnotami $0$ a $1$ a $p$ příznaků $X_1, X_2, \\ldots, X_p$ s konstantním $X_0 = 1$.\n",
    "\n",
    "* Namísto hodnoty vysvětlované proměnné $Y \\in \\{0,1\\}$ se snažíme predikovat pravděpodobnost, že při zadaných hodnotách příznaků $X_i$ má $Y$ hodnotu $1$, tj. číslo $P(Y = 1 \\mid \\boldsymbol{x},\\boldsymbol{w})$ kde $\\boldsymbol{w}$ je vektor parametrů modelu.\n",
    "* Pro dané hodnoty $\\boldsymbol{x}^T = (x_0, x_1, \\ldots, x_p)$ a koeficienty $\\boldsymbol{w}^T = (w_0, w_1, \\ldots, w_p)$ má model tvar\n",
    "$$\n",
    "P(Y = 1 \\mid \\boldsymbol{x},\\boldsymbol{w}) = \\frac{e^{\\boldsymbol{w}^T \\boldsymbol{x}}}{1 + e^{\\boldsymbol{w}^T \\boldsymbol{x}}}.\n",
    "$$\n",
    "* Je-li $P(Y = 1 \\mid \\boldsymbol{x},\\boldsymbol{w})$ větší než $\\frac{1}{2}$, rozhodneme se pro $Y = 1$, je-li menší než $\\frac{1}{2}$, pro $Y = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sigmoida (standardní logistická funkce)\n",
    "\n",
    "Nejprve se podíváme na základní matematické vlastnosti sigmoidy, která je definována vztahem\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{e^x}{1 + e^x} = \\frac{1}{1 + e^{-x}}, \\qquad D_f = \\mathbb{R}, \\qquad H_f = (0,1).\n",
    "$$\n",
    "\n",
    "### Úkol - odvoďte si, čemu je rovna derivace sigmoidy.\n",
    "Derivaci klasicky spočítejte a pak se podíváme, jak ji spočítá knihovna `sympy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "x = sympy.symbols('x'); a = 10;\n",
    "\n",
    "f = 1/(1+sympy.exp(-x)) # sigmoida\n",
    "df = sympy.diff(f,x) # derivace sigmoidy\n",
    "\n",
    "p1 = sympy.plot(f,(x,-a,a), line_color = 'b', title = 'graf sigmoidy a její derivace', legend = ['f(x)'],show = False, size = (10,5))\n",
    "p2 = sympy.plot(df,(x,-a,a),line_color= 'r',legend = ['df(x)'], show = False)\n",
    "p1.extend(p2)\n",
    "p1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Limity v $\\pm \\infty$:\n",
    "$$ \\lim_{x \\to +\\infty} f(x) = 1, \\qquad \\lim_{x \\to -\\infty} f(x) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "display(sympy.limit(f,x,sympy.oo))\n",
    "display(sympy.limit(f,x,-sympy.oo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rovnice $f(x) = \\frac{1}{2}$ má jediné řešení $x = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sympy.solve(f-1/2,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Derivace v $0$ je $f'(0) = \\frac{1}{4}$. Rovnice tečny v bodě nula je $y = f(0) + f'(0)(x-0)=\\frac{x}{4} + \\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('Rovnice tečny v bodě 0:')\n",
    "display(f.subs(x,0) + df.subs(x,0)*(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Umělá data\n",
    "\n",
    "Pro demonstraci fungování logistické regrese si vygenerujeme umělá data se dvěma příznaky $X_0$ a $X_1$ a binární vysvětlovanou proměnnou.\n",
    "\n",
    "Je to směs dvou dvourozměrných Gaussiánů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# funkce, která připraví dataset\n",
    "def get_sample(n, random_seed):\n",
    "    np.random.seed(random_seed)  # zajistí replikovatelnost\n",
    "    n1 = int(n/2)\n",
    "    n2 = n - n1\n",
    "    mean1 = [-20, 20]\n",
    "    cov1 = [[3000, 850], [850, 1000]]\n",
    "    mean2 = [10, -10]\n",
    "    cov2 = [[3000, 850], [850, 1000]]\n",
    "    X1 = np.random.multivariate_normal(mean1, cov1, n1)\n",
    "    y1 = np.zeros(n1,dtype=\"int\")\n",
    "    X2 = np.random.multivariate_normal(mean2, cov2, n2)\n",
    "    y2 = np.ones(n2,dtype=\"int\")\n",
    "\n",
    "    X = np.concatenate((X1,X2), axis=0)\n",
    "    y = np.concatenate((y1,y2), axis=0)\n",
    "    return X, y\n",
    "\n",
    "# vytvoříme úvodní dataset\n",
    "X, y = get_sample(300, 50)\n",
    "\n",
    "# rozdělíme ho na trénovací a validační\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.5, random_state = 42)\n",
    "\n",
    "# zobrazení velikosti výsledných dat\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Zobrazení datasetu\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
    "plt.scatter(Xtrain[:, 0], Xtrain[:, 1], c=ytrain, cmap=cmap_bold)\n",
    "plt.xlabel('$X_0$')\n",
    "plt.ylabel('$X_1$')\n",
    "plt.title(\"Trénovací množina\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Logistická regrese \n",
    "\n",
    "  * Logistická regrese je v `sklearn.linear_model` jako `LogisticRegression`.\n",
    "  * Používá se pak klasicky dle obvyklého API modelů v `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfLOG = LogisticRegression(solver='newton-cg')\n",
    "clfLOG.fit(Xtrain,ytrain)\n",
    "print('Koeficienty w_1 a w_2:', clfLOG.coef_)\n",
    "print('Intercept w_0:', clfLOG.intercept_,\"\\n\")\n",
    "\n",
    "print('Klasifikace prvních 10 datových bodů z validační množiny:')\n",
    "print('Predikce:', clfLOG.predict(Xval[:10,:]))\n",
    "print('\\nPredikce pravděpodobností:\\n', clfLOG.predict_proba(Xval[:10,:]))\n",
    "print('\\nSkutečné labely:', yval[:10])\n",
    "\n",
    "print('\\nValidační přesnost:', clfLOG.score(Xval,yval))\n",
    "print('Trénovací přesnost:', clfLOG.score(Xtrain,ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Rozhodovací hranice logistické regrese\n",
    "\n",
    "Z vlastností sigmoidy plyne, že rozhodovací hranice\n",
    "$$\n",
    "P(Y = 1 \\mid \\boldsymbol{x},\\boldsymbol{w}) = \\frac{e^{\\boldsymbol{w}^T \\boldsymbol{x}}}{1 + e^{\\boldsymbol{w}^T \\boldsymbol{x}}} = \\frac{1}{2}\n",
    "$$\n",
    "je nadrovina\n",
    "$$\n",
    "\\boldsymbol{w}^T \\boldsymbol{x} = w_0 + w_1 x_1 + \\cdots + w_p x_p = 0,\n",
    "$$\n",
    "v prostoru $\\mathbb{R}^{p}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rozhodovací hranicí je přímka $w_0 + w_1 \\cdot x + w_2 \\cdot y = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def fun(x, intercept, coef1, coef2):\n",
    "    y = (-1/coef2)*(intercept + coef1*x)\n",
    "    return y\n",
    "# uděláme vektorovou funkci aby šlapala na ndarray\n",
    "vfun = np.vectorize(fun)\n",
    "\n",
    "xgrid = np.linspace(-200, 200, 200)\n",
    "plt.scatter(Xtrain[:, 0], Xtrain[:, 1], c=ytrain, cmap=cmap_bold)\n",
    "plt.plot(xgrid, vfun(xgrid, clfLOG.intercept_, clfLOG.coef_[0,0], clfLOG.coef_[0,1]), 'k-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(Xval[:, 0], Xval[:, 1], c=yval, cmap=cmap_bold);\n",
    "plt.xlabel('$X_0$') \n",
    "plt.ylabel('$X_1$')\n",
    "plt.title(\"Původní data validační množiny\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(Xval[:, 0], Xval[:, 1], c=clfLOG.predict(Xval), cmap=cmap_bold);\n",
    "plt.plot(xgrid, vfun(xgrid, clfLOG.intercept_, clfLOG.coef_[0,0], clfLOG.coef_[0,1]), 'k-')\n",
    "plt.xlabel('$X_0$')\n",
    "plt.ylabel('$X_1$')\n",
    "plt.title(\"Predikované hodnoty validační množiny\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rozhodovací hranice KNN\n",
    "\n",
    "  * Použijeme pro srovnání KNN, které známe, a ukážeme si, jak vypadá hranice, kde se mění rozhodnutí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "h = 0.2  # step size in the mesh\n",
    "n_neighbors = 5\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "\n",
    "def plotkNN(weights):\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clfKNN = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clfKNN.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    x_min, x_max = Xtrain[:, 0].min() - 1, Xtrain[:, 0].max() + 1\n",
    "    y_min, y_max = Xtrain[:, 1].min() - 1, Xtrain[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clfKNN.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(Xtrain[:, 0], Xtrain[:, 1], c=ytrain, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xlabel('$X_0$')\n",
    "    plt.ylabel('$X_1$')\n",
    "    plt.title(\"2-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "for weights in ['uniform', 'distance']:\n",
    "    plotkNN(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plotkNN('distance')\n",
    "plt.plot(xgrid, vfun(xgrid, clfLOG.intercept_, clfLOG.coef_[0,0], clfLOG.coef_[0,1]), 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rozhodovací hranice rozhodovacího stromu\n",
    "\n",
    "  * Pro srovnání se ještě podívejme na rozhodovací stromy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(121); plt.scatter(Xtrain[:, 0], Xtrain[:, 1], c=ytrain, cmap=cmap_bold);\n",
    "plt.xlabel('$X_0$'); plt.ylabel('$X_1$');\n",
    "plt.title(\"Původní data\")\n",
    "plt.subplot(122); plt.scatter(Xtrain[:, 0], Xtrain[:, 1], c=dt.predict(Xtrain), cmap=cmap_bold);\n",
    "plt.xlabel('$X_0$'); plt.ylabel('$X_1$')\n",
    "plt.title(\"Predikované hodnoty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Uložení výsledného modelu\n",
    "\n",
    "* V případě přenesení naučeného modelu do produkce či prostě při potřebě uložení výsledků práce je dobré moci si uložit výsledný model do souboru, ze kterého jej lze později načíst.\n",
    "* Lze využít balíček [pickle](https://docs.python.org/3/library/pickle.html#module-pickle).\n",
    "* Pro složitější struktury lze použít [joblib](https://pypi.org/project/joblib/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os, pickle # package for serializing objects in Python\n",
    "filename = 'clfLOG.pickle'\n",
    "pickle.dump(clfLOG, open(filename, 'wb')) # saving the model\n",
    "\n",
    "clfLOG_loaded = pickle.load(open(filename, 'rb'))\n",
    "print('Coeficients of original model:', clfLOG.coef_, clfLOG.intercept_)\n",
    "print('Coefficients of loaded model:', clfLOG_loaded.coef_, clfLOG_loaded.intercept_)\n",
    "print('Filesize: ', os.stat(filename).st_size, 'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Úkol - parciální derivace a gradient\n",
    "\n",
    "**Úkol**: Najděte gradient funkce $\\ell(\\boldsymbol{w})$ (viz přednášku):\n",
    "$$\n",
    "    \\ell(\\boldsymbol{w}) = \\sum_{i = 1}^N \\left(Y_i \\ln \\left( \\frac{e^{\\boldsymbol{w}^T \\boldsymbol{x}_i}}{1 + e^{\\boldsymbol{w}^T \\boldsymbol{x}_i}} \\right) + (1 - Y_i) \\ln \\left( \\frac{1}{1 + e^{\\boldsymbol{w}^T \\boldsymbol{x}_i}} \\right)\\right).\n",
    "$$\n",
    "  * Pokuste se přepsat výsledek do maticového tvaru\n",
    "  $$\n",
    "  \\nabla \\ell(\\boldsymbol{w}) = \\mathbf{X}^T (\\boldsymbol Y - \\boldsymbol P),\n",
    "  $$\n",
    "  kde\n",
    "  $$\n",
    "\\boldsymbol P = \\big(p_1(\\boldsymbol x_1,\\boldsymbol w), \\dotsc, p_1(\\boldsymbol x_N,\\boldsymbol w)\\big)^T\n",
    "$$\n",
    "a\n",
    "$$\n",
    "p_1(\\boldsymbol x_i,\\boldsymbol w) = \\frac{e^{\\boldsymbol{w}^T \\boldsymbol{x}_i}}{1 + e^{\\boldsymbol{w}^T \\boldsymbol{x}_i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úkol - trénovaní logistické regrese gradientním sestupem\n",
    "\n",
    "Využijte předchozího výsledku k ručnímu trénování logistické regrese. Pozor, že při metodě maximální věrohodnosti účelovou funkci (logaritmus věrohodnostní funkce) $\\ell(\\boldsymbol w)$ **maximalizujeme**\n",
    "\n",
    "Využijte implementaci `scipy.special.expit` sigmoidy a poté zkuste klasický gradientní sestup, ve kterém děláte následující update: \n",
    "$$\\boldsymbol w_{i+1} = \\boldsymbol w_{i} + \\alpha \\cdot \\nabla \\ell(\\boldsymbol{w}_i)$$\n",
    "pro zvolenou learning rate $\\alpha$. \n",
    "\n",
    "Zkuste také adaptivní verzi, při které $\\alpha_i = \\frac{\\alpha}{1 + i}$.\n",
    "\n",
    "V obou případech se podívejte na hodnotu výsledného gradientu a spočtěte přesnost na trénovací i validační množině. Porovnejte ji s předchozím modelem z knihovny `sklearn` (i gradient i přesnosti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "# Váš kód zde\n",
    "\n",
    "# Matice X\n",
    "XX = ...\n",
    "\n",
    "# Vektor Y\n",
    "YY = ...\n",
    "\n",
    "# gradient\n",
    "def get_grad(w, XX, YY):\n",
    "    ...\n",
    "\n",
    "w_hat = ...\n",
    "\n",
    "alpha = ...\n",
    "for i in range(??):\n",
    "    # get gradient\n",
    "    ...\n",
    "\n",
    "    \n",
    "print('Odhad: ', w_hat.T) \n",
    "print('Gradient: ', get_grad(w_hat, XX, YY).T)\n",
    "\n",
    "Ptrain = ...\n",
    "Yhattrain = ...\n",
    "\n",
    "XXval = ...\n",
    "Pval = ...\n",
    "Yhatval = ...\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('\\nTrénovací přesnost:', accuracy_score(ytrain, Yhattrain))\n",
    "print('Validační přesnost:', accuracy_score(yval, Yhatval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podívejme se, jak je na tom model a jeho parametry z knihovny `sklearn`. Podívejme se také na velikost gradientu v tomto odhadu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_h2 = w_hat\n",
    "w_h2[0,0] = clfLOG.intercept_\n",
    "w_h2[1:,0] = clfLOG.coef_.T\n",
    "\n",
    "print('Odhad: ', w_h2.T) \n",
    "print('Gradient: ', get_grad(w_h2, XX, YY).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trénovací a validační přesnosti pro model ze `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Trénovací přesnost ze sklearn:', clfLOG.score(Xtrain,ytrain))\n",
    "print('Validační přesnost ze sklearn:', clfLOG.score(Xval,yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
