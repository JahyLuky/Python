{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cvičení 04 - k-nejbližších sousedů (kNN)\n",
    "\n",
    "V tomto cvičení se budeme zabývat metodou $k$-nejbližších sousedů pro klasifikaci i regresi.\n",
    "V regresním případě si můžeme princip metody představit na tomto obrázku:\n",
    "\n",
    "<center><img src=\"img/knn.svg\" width=\"10%\"></center>\n",
    "<center>(zdroj: https://commons.wikimedia.org/wiki/File:KnnClassification.svg, autor: Antti Ajanki)</center>\n",
    "\n",
    "\n",
    "Jde o to, využít vhodnou metriku (vzdálenost) k nalezení $k$-nejbližších sousedů a poté z jejich hodnot cílové proměnné predikovat cílovou proměnnou pro náš bod.\n",
    "\n",
    "### Hyperparametry:\n",
    "- $k$ - počet nejbližších sousedů (např. 5),\n",
    "- **vzdálenost** - nejčastěji Eukleidovská metrika,\n",
    "- **vážení** - zda při výpočtu nejčetnější hodnoty (klasifikace) nebo průměrné hodnoty (regrese) používat vážení, a jaké případně využít (např. převrácenou hodnotou vzdálenosti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasifikace Iris datasetu\n",
    "\n",
    "V této části se budemě věnovat klasifikační úloze na standardním datasetu **Iris**\n",
    "[https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set)\n",
    "Teto dataset obsahuje záznamy o šířkách a délkách korunních (petal) a kališních (sepal) lístků kosatců. V datasetu se vyskytují tři druhy kosatců (setosa, versicolor a virginica) a cílem je klasifikovat na základě těchto 4 příznaků o jaký druh se jedná.\n",
    "\n",
    "<center><img src=\"img/iris-dataset.png\" width=\"50%\"></center>\n",
    "<center>(zdroj: https://machinelearninghd.com/iris-dataset-uci-machine-learning-repository-project/)</center>\n",
    "\n",
    "<center><img src=\"img/iris_measurements.png\" width=\"10%\"></center>\n",
    "<center>(zdroj: https://kedro.readthedocs.io/en/0.17.5/02_get_started/05_example_project.html)</center>\n",
    "\n",
    "Dataset načteme pomocí modulu `sklearn.datasets`. \n",
    "Práci si ale trochu ztížíme a první příznak převedeme na milimetry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(f\"Načtené rozměry, X: {X.shape}, y: {y.shape}\")\n",
    "\n",
    "print('Ukázka dat:')\n",
    "display(X[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Převedeme první příznak z centimetrů na milimetry\n",
    "X[:, 0] *= 10\n",
    "\n",
    "print(f\"Rozměry, X: {X.shape}, y: {y.shape}\")\n",
    "print('Ukázka dat:')\n",
    "display(X[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocí již dobře známé funkce `train_test_split` rozdělíme data na trénovací a validační v poměru 60:20:20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(X, y, test_size=0.5, random_state=random_seed)\n",
    "Xval, Xtest, yval, ytest = train_test_split(Xval, yval, test_size=0.5, random_state=random_seed)\n",
    "\n",
    "print(f\"Train rozměry, X: {Xtrain.shape}, y: {ytrain.shape}\")\n",
    "print(f\"Val rozměry, X: {Xval.shape}, y: {yval.shape}\")\n",
    "print(f\"Test rozměry, X: {Xtest.shape}, y: {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data si můžeme vizualizovat pomocí scatter plotu. Vidíme, že dvě ze tříd se mírně překrývají. To by ale pro kNN klasifikátor (např. oproti lineární separaci) neměl být problém."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Xtrain[:, 0], Xtrain[:, 2], c=ytrain, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak ale uvidíme za chvíli, kNN je velice citlivé na různě velké rozsahy hodnot jednotlivých příznaků.\n",
    "\n",
    "### Úkol: Ruční implementace KNN\n",
    "\n",
    "Zkusme si vlastní implementaci metody nejbližších sousedů. Pro jednoduchost použijeme Eukleidovskou metriku a nebudeme dělat žádné vážení.\n",
    "\n",
    "Hint: Použijte `numpy.argpartition` a `scipy.stats.mode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(X, k, Xtrain, ytrain):\n",
    "    \"\"\"\n",
    "    X je matice M x p kde pro každý z M bodů chceme na základě p příznaků predikovat\n",
    "    k je počet nejbližších sousedů\n",
    "    Xtrain je N x p matice trénovacích bodů a ytrain je vektor p hodnot vysvětlované proměnné\n",
    "    \n",
    "    vrací vektor predikcí o délce M \n",
    "    \"\"\"\n",
    "    y = np.zeros((X.shape[0],), np.int32)\n",
    "    # Váš kód zde\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return y\n",
    "\n",
    "# provedeme predikci\n",
    "y_pred = knn_predict(Xval, 5, Xtrain, ytrain)\n",
    "\n",
    "# Ověříme přesnost na validační množině\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(yval, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Získali jsme rozumný výsledek. Pro větší data, ale naše implementace nebude výpočetně příliš optimální. Zkusme si tedy nyní to samé provést pomocí standardní knihovny ze `sklearn` a ověřme, že dostaneme stejný výsledek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementace KNeighborsClassifier ve scikit\n",
    "Nyní použijeme `KNeighborsClassifier` z knihovny `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(yval, clf.predict(Xval)):0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dostali jsme stejný výsledek, jako naší _ruční_ implementací! \n",
    "\n",
    "V obou případech ale přesnost bohužel příliš vysoká.\n",
    "Pojďme se nyní zaměřit na vliv přeškálování prvního příznaku, které jsme provedli na začátku.\n",
    "\n",
    "Zkusme nejprve celý postup zreplikovat bez toho **poškození**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "Xtrain_clean = copy.deepcopy(Xtrain)\n",
    "Xtrain_clean[:, 0] *= 0.1\n",
    "\n",
    "Xval_clean = copy.deepcopy(Xval)\n",
    "Xval_clean[:, 0] *= 0.1\n",
    "\n",
    "print('Ukázka dat:')\n",
    "display(Xtrain_clean[:5,:])\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "clf.fit(Xtrain_clean, ytrain)\n",
    "print(f\"Validation accuracy: {metrics.accuracy_score(yval, clf.predict(Xval_clean)):0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že jsme dostali lepší výsledek. Prvotní převedení prvního příznaku do milimetrů tedy z hledika predikce uškodilo.\n",
    "\n",
    "### Normalizace dat\n",
    "Zkusme si nyní obecný přístup, který více odpovídá realitě, kdy _poškození_ dat nemůžeme prostě vrátit. \n",
    "\n",
    "Na přednášce jsme si říkali, že pro _narovnání_ číselných rozsahů jednotlivých příznaků může mít smysl použít normalizaci.\n",
    "\n",
    "Zkusíme si tedy nyní **min-max normalizaci**. To v Pythonu uděláme pomocí třídy `MinMaxScaler` z modulu `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Min-max scaler nafitujeme na trénovacích datech\n",
    "scaler = MinMaxScaler()\n",
    "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# Následně stejnou transformaci aplikujeme i na validační data\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "\n",
    "# Natrénujeme model na transformovaných datech\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "print(f\"Validation accuracy of normalized model: {clf.score(Xval_scaled, yval):0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taková přesnost už je velice pěkná. Pojďme si ještě vyzkoušet **standardizaci** jako další z používaných typů normalizace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Min-max scaler nafitujeme na trénovacích datech\n",
    "scaler = StandardScaler()\n",
    "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# Následně stejnou transformaci aplikujeme i na validační data\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "\n",
    "# Natrénujeme model na transformovaných datech\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(Xtrain_scaled, ytrain)\n",
    "\n",
    "print(f\"Validation accuracy of normalized model: {clf.score(Xval_scaled, yval):0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že jsme dostali totožný výsledek. To v praxi nemusí být vždy tak. Jeden nebo druhý (nebo) žádný způsob normalizace může dávat lepší výsledky.\n",
    "\n",
    "### Úkol: podívejte se nyní na vliv hyperparametrů na výkonnost predikce\n",
    "\n",
    "Zaměřte se především na parametr $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = []\n",
    "train_acc = []\n",
    "\n",
    "kneighbors = ...\n",
    "\n",
    "# Váš kód zde\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.plot(kneighbors, train_acc,'or-') #o: body, r: barva, -: spojení bodů linkou\n",
    "plt.plot(kneighbors, val_acc,'ob-')\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pár bodů k zamyšlení\n",
    "\n",
    "- Člověka by mohlo napadnout provést normalizaci na celém trénovacím datasetu a až potom provádět validaci. V tu chvíli by ale validační chyba nebyla objektivní. (Je to podobné, jako bychom při trénování používali i testovací data.)\n",
    "- Min-max normalizace, případně standardizace není všespásná, jedná se o obyčejnou lineární transformaci. Obecně jí dělají problém odlehlé hodnoty (outlieři). V tu chvíli je vhodné buď outliery nejprve odstranit, nebo použít robustnější metodu normalizace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresní úloha s datasetem house prices\n",
    "\n",
    "Nyní se podívejme na predikci spojité vysvětlované proměnné u datasetu house prices.\n",
    "\n",
    "Metodu kNN nelze přímo použít, pokud máme v datasetu jiné než číselné příznaky.\n",
    "Protože, jsme s tímto datasetem již pracovali, pro urychlení přebereme základní předzpracování z přechozího cvičení.\n",
    "\n",
    "V prvním přiblížení použijeme na nominální příznaky **one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_houses_dataset(one_hot = True, fill_na = True):\n",
    "    df = pd.read_csv('house-prices-train.csv')\n",
    "\n",
    "    qual_category = pd.api.types.CategoricalDtype(categories=['Po', 'Fa', 'TA', 'Gd', 'Ex'], ordered=True)\n",
    "    for col in df.select_dtypes('object').columns:\n",
    "        if col.endswith(\"Qual\") or col.endswith(\"Qu\") or col.endswith(\"QC\") or col.endswith(\"Cond\"):\n",
    "            df[col] = df[col].astype(qual_category)\n",
    "\n",
    "    for col in df.select_dtypes('category').columns:\n",
    "        df[col] = df[col].cat.codes\n",
    "\n",
    "    # ONE-HOT encoding\n",
    "    if one_hot:\n",
    "        df = pd.get_dummies(df)\n",
    "    # Missing values\n",
    "    if fill_na:\n",
    "        df = df.fillna('-1')\n",
    "    return df\n",
    "\n",
    "# načteme si dataset\n",
    "df = get_houses_dataset()\n",
    "\n",
    "# Split the training dataset into 60% train and 40% rest\n",
    "Xtrain, Xrest, ytrain, yrest = train_test_split(df.drop(columns=['SalePrice']), df.SalePrice, test_size=0.4, random_state=random_seed)\n",
    "\n",
    "# Split the rest of the data into 0.6*0.4=24% validation, 0.4*0.4=16% test\n",
    "Xtest, Xval, ytest, yval = train_test_split(Xrest, yrest, test_size=0.6, random_state=random_seed)\n",
    "\n",
    "print(f\"Train rozměry, X: {Xtrain.shape}, y: {ytrain.shape}\")\n",
    "print(f\"Val rozměry, X: {Xval.shape}, y: {yval.shape}\")\n",
    "print(f\"Test rozměry, X: {Xtest.shape}, y: {ytest.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro modelování použijeme implementaci `KNeighborsRegressor` ze `sklearn`. Než to ale uděláme, zkontrolujeme, že opravdu máme všude validní data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf = KNeighborsRegressor(n_neighbors=5)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "train_rmse_tree = mean_squared_error(ytrain, clf.predict(Xtrain), squared = False)\n",
    "valid_rmse_tree = mean_squared_error(yval, clf.predict(Xval), squared = False)\n",
    "print(f\"RMSE (train): \\t{train_rmse_tree:.0f}\")\n",
    "print(f\"RMSE (valid): \\t{valid_rmse_tree:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro porovnání si připomeňme hodnoty pro rozhodovací strom z minulého cvičení: \n",
    "\n",
    "RMSE (train): 23 963\n",
    "\n",
    "RMSE (valid): 41 145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Úkol: zkuste použít normalizaci, změnit počet nejbližších sousedů, případně jinou metriku\n",
    "\n",
    "Diskutujte vliv jednotlivých operací"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Váš kód zde\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Trénování\n",
    "clf = KNeighborsRegressor(n_neighbors=5)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "train_rmse_tree = mean_squared_error(ytrain, clf.predict(Xtrain), squared = False)\n",
    "valid_rmse_tree = mean_squared_error(yval, clf.predict(Xval), squared = False)\n",
    "print(f\"RMSE (train): \\t{train_rmse_tree:.0f}\")\n",
    "print(f\"RMSE (valid): \\t{valid_rmse_tree:.0f}\")\n",
    "\n",
    "\n",
    "# A další hraní\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prokletí dimenzionality\n",
    "\n",
    "- Normalizovaná data jsou rozprostřena v $n$-rozměrné krychli o délce strany 1.\n",
    "- Diagonála této krychle (za použití euklidovské vzdálenosti) měrí $\\sqrt{n}$. To je zároveň nejvyšší možná vzdálenost, jakou mezi sebou dva body mohou mít.\n",
    "- Prokletí dimenzionality znamená, že se zvyšující se dimenzí se vzdálenost k nejbližšímu sousedovi zvyšuje.\n",
    "- Tento efekt můžeme poměrně dobře demonstrovat. Pro různé počty příznaků napočítáme poměr průměrné vzdálenosti k nejbližšímu sousedovi oproti diagonále krychle. (Dostáváme tedy vzdálenost relativní vůči maximální možné.) To samé můžeme spočítat i pro nejvzdálenější sousedy a pro průměr všech sousedů."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_houses_dataset()\n",
    "# Data pro jednoduchost rozdělíme na trénovací a validační\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(df.drop(columns=['SalePrice']), df.SalePrice, test_size=0.4, random_state=random_seed)\n",
    "\n",
    "# Scaler opět nafitujeme podle trénovacích dat a následně transformujeme i validační\n",
    "scaler = MinMaxScaler()\n",
    "Xtrain = pd.DataFrame(scaler.fit_transform(Xtrain), index=Xtrain.index, columns=Xtrain.columns)\n",
    "Xval = pd.DataFrame(scaler.transform(Xval), index=Xval.index, columns=Xval.columns)\n",
    "\n",
    "min_dist_ratio = []\n",
    "max_dist_ratio = []\n",
    "mean_dist_ratio = []\n",
    "for n in range(1, 80 + 1):\n",
    "    # Natrénujeme model pro různé počty příznaků\n",
    "    model = KNeighborsRegressor(n_neighbors=10, p=2)\n",
    "    model.fit(Xtrain.iloc[:, 0:n], ytrain)\n",
    "    # Změříme vzdálenost pro všechny body z validační množiny\n",
    "    dist, nn = model.kneighbors(Xval.iloc[:, 0:n])\n",
    "    # Spočítáme průměrné vzdálenosti\n",
    "    min_dist_ratio.append(np.mean(np.min(dist, axis=1)) / math.sqrt(n))\n",
    "    max_dist_ratio.append(np.mean(np.max(dist, axis=1)) / math.sqrt(n))\n",
    "    mean_dist_ratio.append(np.mean(np.mean(dist, axis=1)) / math.sqrt(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.xlabel('dimensions')\n",
    "plt.plot(range(1, len(min_dist_ratio) + 1), min_dist_ratio, 'go-', alpha=0.25, label='Avg. distance to nearest neighbor')\n",
    "plt.plot(range(1, len(mean_dist_ratio) + 1), mean_dist_ratio, 'bo-', label='Avg. distance to mean of all neighbors')\n",
    "plt.plot(range(1, len(max_dist_ratio) + 1), max_dist_ratio, 'ro-', alpha=0.25, label='Avg. distance to farthest neighbor')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*K zamyšlení: Proč křivka občas klesá? (Zkuste místo relativní vzdálenosti použít absolutní.)*\n",
    "\n",
    "**Úkol:** Zkuste experimentovat s hyperparametrem `n_neighbors`. Jaký má jeho hodnota vliv na průměrnou vzdálenost? Vykreslete do jednoho grafu křivky pro více hodnot hyperparametru a porovnejte je."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
